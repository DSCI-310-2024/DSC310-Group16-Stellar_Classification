{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Stellar Classification using Photometric data\n",
        "author: 'Olivia Lam, Aron Braham, Lucy Liu, and Viet Ngo'\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "  pdf:\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "bibliography: references.bib\n",
        "editor:\n",
        "  markdown:\n",
        "    wrap: 72\n",
        "params:\n",
        "  echo: false\n",
        "---"
      ],
      "id": "9b8b7305"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this report, we attempt to build a classification model using\n",
        "logistic regression which uses photo metric measurements from telescopes\n",
        "to classify stars under the Morgan-Keenan system. Our final classifier\n",
        "performed poorly with final accuracy of `{python} rounded_acc` on testing data set with a tendency to classify stars as one class cooler than its actual class type. Our model can only classify stars into four main classes due to the small sample size. It is recommended that further study using\n",
        "larger sample sizes and methods to improve the classification model.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Current and future astronomical surveys will observe hundred of\n",
        "thousands of objects each year. Due to the massive amount of\n",
        "spectroscopic and photometric data produced, an automated stellar\n",
        "classification process has become important in the field of astronomy in\n",
        "the past few years.\n",
        "\n",
        "In astronomy, understanding the spectral characteristics of celestial\n",
        "objects serves as a fundamental pillar for unraveling the mysteries of\n",
        "the cosmos. Spectral classification, a cornerstone of astronomical\n",
        "research, enables us to discern the chemical composition, temperature,\n",
        "and evolutionary stage of stars, galaxies, and other celestial bodies.\n",
        "In the earliest days it was based on mass and temperature; however, our\n",
        "modern classification system has evolved and we classify stars based on\n",
        "the Morganâ€“Keenan (MK) system [@morgan1942atlas] which group stars into\n",
        "7 classes based on their spectral characteristics. Under the MK system,\n",
        "astronomers analyse electromagnetic radiation from stars to determine\n",
        "its class. These electromagnetic spectrum have dark lines to determine\n",
        "which and how abundant elements are present in the star. The seven\n",
        "classes in the MK system - O, B, A, F, G, K, and M - are sequenced from\n",
        "the hottest (O type) to the coolest (K type) which also exhibits a\n",
        "certain characteristic that is very visible - colour. Hence in this\n",
        "report, we will classify stars using photometric data and in the\n",
        "Discussion section, we will evaluate whether this is a reliable\n",
        "alternative for the traditional method of comparing the best fit of the\n",
        "spectra to that of templates using statistical tests\n",
        "[@duan2009automated].\n",
        "\n",
        "### Definitions\n",
        "\n",
        "**Photometry**: the measurement of the flux or intensity of an\n",
        "astronomical object's electromagnetic radiation\n",
        "\n",
        "The photo metric system we're using to classify star types is the\n",
        "*Sloan* system [@kent1994sloan] used by the Sloan Digital Sky Survey.\n",
        "The system measures the intensity of electromagnetic radition from stars\n",
        "at 5 bands: - *u* (345nm) - *g* (475nm which is a light blue in the\n",
        "visible spectrum) - *r* (622nm which is orange) - *i* (763nm which is\n",
        "deep red) - *z* (905nm)\n",
        "\n",
        "## Methods & Results\n",
        "\n",
        "### Data\n",
        "\n",
        "This report has made use of the NASA Exoplanet Archive, which is\n",
        "operated by the California Institute of Technology, under contract with\n",
        "the National Aeronautics and Space Administration under the Exoplanet\n",
        "Exploration Program. NASA Exoplanet Archive collects data from various\n",
        "sources, including ground-based observatories and space telescopes such\n",
        "as the Kepler Space Telescope and the Transiting Exoplanet Survey\n",
        "Satellite (TESS). The dataset is we're using is their [Planetary Systems\n",
        "dataset](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=PS)\n",
        "which has the columns of names, spectral type and measurements using\n",
        "Sloan photometric system selected.\n",
        "\n",
        "The Python programming language [@van1995python] and the following\n",
        "Python packages were used to perform the analysis: `matplotlib`\n",
        "[@hunter2007matplotlib], `scikit-learn` [@pedregosa2011scikit] and\n",
        "`Pandas` [@mckinney2010data].\n",
        "\n",
        "### Imports\n",
        "\n",
        "First of all, let's import the packages we will use to carry out the\n",
        "analysis and download the dataset. For our analysis we primarily used\n",
        "`sklearn` and `pandas` for our classification analysis as well as\n",
        "`matplotlib` for our visualizations.\n"
      ],
      "id": "8959fb77"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "50242e10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading the Dataset\n",
        "\n",
        "We then download the dataset of interest: the Expoplanet Systems dataset\n",
        "from NASA, containing information about measurements of planets and\n",
        "stars. We are interested in the spectral type of stars given a subset of\n",
        "these measurements.\n"
      ],
      "id": "365abac6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-read-data\n",
        "#| tbl-cap: Table of our Initial Data\n",
        "\n",
        "exoplanet_data = pd.read_csv(\"data/raw/2024-03-20_planet-systems.csv\")\n",
        "Markdown(exoplanet_data.to_markdown(index = False))"
      ],
      "id": "tbl-read-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data EDA and Wrangling\n",
        "\n",
        "This dataset from NASA's Exoplanet Archive include all planets and\n",
        "stars. Therefore we will wrangle the dataset such that it only contain\n",
        "stars with Sloan magnitudes for photometric measurements.\n",
        "\n",
        "Below in @tbl-cleaned-data our preprocessing included dropping NA values from our `spec_type` and band star brightness features. We are also only interested in the first letter of the spectral type, which becomes our y value later in the analysis, so we modified that feature as well.\n"
      ],
      "id": "c254fd02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-cleaned-data\n",
        "#| tbl-cap: Table of our Cleaned Dataset\n",
        "\n",
        "cleaned_data = pd.read_csv(\"data/processed/planet-systems.csv\")\n",
        "Markdown(cleaned_data.to_markdown(index = False))"
      ],
      "id": "tbl-cleaned-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: In order to run classification models on our dataset, we had\n",
        "to remove the NA values from our magnitudes. We were planning to\n",
        "incorporate `SimpleImputer()` into our pipeline during data\n",
        "preprocessing, but about 2200 rows contained NA values, so we thought it\n",
        "was best to simply drop them. This explains the drastic decrease in\n",
        "observations.\n",
        "\n",
        "### Variable Descriptions:\n",
        "\n",
        "`st_spectype`: Classification of the star based on their spectral\n",
        "characteristics following the Morgan-Keenan system\n",
        "\n",
        "`sy_umag`: Brightness of the host star as measured using the Sloan\n",
        "Digital Sky Survey (SDSS) u band, in units of magnitudes\n",
        "\n",
        "`sy_gmag`: Brightness of the host star as measured using the Sloan\n",
        "Digital Sky Survey (SDSS) g band, in units of magnitudes\n",
        "\n",
        "`sy_rmag`: Brightness of the host star as measured using the Sloan\n",
        "Digital Sky Survey (SDSS) r band, in units of magnitudes\n",
        "\n",
        "`sy_imag`: Brightness of the host star as measured using the Sloan\n",
        "Digital Sky Survey (SDSS) i band, in units of magnitudes\n",
        "\n",
        "`sy_zmag`: Brightness of the host star as measured using the Sloan\n",
        "Digital Sky Survey (SDSS) z band, in units of magnitudes\n",
        "\n",
        "From our @fig-sy_umag visualization below we can see that our highest\n",
        "stellar value counts was for the *M* class, followed respectively by\n",
        "*K*, *G*, and *F*.\n",
        "\n",
        "![`Histogram of Star Count Values`](results/figures/star_count_hist.png){#fig-sy_umag\n",
        "width=\"50%\"}\n",
        "\n",
        "Now we will explore the features and boxplots of each band's magnitude\n",
        "for our four types of stellar classifications.\n"
      ],
      "id": "3ad2d490"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-sy-umag\n",
        "#| tbl-cap: Table of sy_umag Features\n",
        "\n",
        "sy_umag = pd.read_csv(\"results/figures/sy_umag.csv\")\n",
        "Markdown(sy_umag.to_markdown(index = False))"
      ],
      "id": "tbl-sy-umag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Box Plot of `sy_umag`](results/figures/sy_umag.png){width=\"50%\"}\n",
        "\n",
        "From boxplot @fig-sy_umag, for *M*-class of stars, the magnitude of the\n",
        "*u*-band is much higher than the remaining classes at 17.3 at the\n",
        "median.\n"
      ],
      "id": "34a668b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-sy-gmag\n",
        "#| tbl-cap: Table of sy_gmag Features\n",
        "\n",
        "sy_gmag = pd.read_csv(\"results/figures/sy_gmag.csv\")\n",
        "Markdown(sy_gmag.to_markdown(index = False))"
      ],
      "id": "tbl-sy-gmag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Box Plot of `sy_gmag`](results/figures/sy_gmag.png){#fig-sy_gmag\n",
        "width=\"50%\"}\n",
        "\n",
        "Again, from boxplot @fig-sy_gmag, for *M*-class of stars, the magnitude\n",
        "of the *g*-band is much higher than the remaining classes at 15.3 at the\n",
        "median.\n"
      ],
      "id": "9aadeee4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-sy-rmag\n",
        "#| tbl-cap: Table of sy_rmag Features\n",
        "\n",
        "sy_rmag = pd.read_csv(\"results/figures/sy_rmag.csv\")\n",
        "Markdown(sy_rmag.to_markdown(index = False))"
      ],
      "id": "tbl-sy-rmag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Box Plot of `sy_rmag`](results/figures/sy_rmag.png){#fig-sy_rmag\n",
        "width=\"50%\"}\n",
        "\n",
        "Again, from boxplot @fig-sy_rmag, for *M*-class of stars, the magnitude\n",
        "of the *r*-band is higher than the remaining classes at 13.4 at the\n",
        "median.\n"
      ],
      "id": "1f621327"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-sy-imag\n",
        "#| tbl-cap: Table of sy_imag Features\n",
        "\n",
        "sy_imag = pd.read_csv(\"results/figures/sy_imag.csv\")\n",
        "Markdown(sy_imag.to_markdown(index = False))"
      ],
      "id": "tbl-sy-imag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Box Plot of `sy_imag`](results/figures/sy_imag.png){#fig-sy_imag\n",
        "width=\"50%\"}\n",
        "\n",
        "From boxplot @fig-sy_imag, for all classes of stars, the magnitude at\n",
        "the *i*-band is similar.\n"
      ],
      "id": "abcf1d30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-sy-zmag\n",
        "#| tbl-cap: Table of sy_zmag Features\n",
        "\n",
        "sy_zmag = pd.read_csv(\"results/figures/sy_zmag.csv\")\n",
        "Markdown(sy_zmag.to_markdown(index = False))"
      ],
      "id": "tbl-sy-zmag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Box Plot of `sy_zmag`](results/figures/sy_zmag.png){#fig-sy_zmag\n",
        "width=\"50%\"}\n",
        "\n",
        "From boxplot @fig-sy_zmag, for all classes of stars, the magnitude at\n",
        "the *i*-band is similar.\n",
        "\n",
        "\n",
        "## Classification Analysis\n",
        "\n",
        "We can now get an informed description of our cleaned data @tbl-describe_datset\n"
      ],
      "id": "482a0a4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-describe_datset\n",
        "#| tbl-cap: Table of Dataset Features\n",
        "\n",
        "describe_data = pd.read_csv(\"results/tables/description_df.csv\")\n",
        "Markdown(describe_data.to_markdown(index = False))"
      ],
      "id": "tbl-describe_datset",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now set our y to be the value we are predicting which is `spec_type` and our predictors will be the following features: `sy_umag`, `sy_gmag`, `sy_rmag`, `sy_imag`, `sy_zmag`. From this we created a 75% train test split to run our data.\n"
      ],
      "id": "aa5c23cf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-y-train-test-values\n",
        "#| tbl-cap: Table of the y Value Counts of our Train-Test Split\n",
        "\n",
        "tts_value = pd.read_csv(\"results/tables/y_values\")\n",
        "Markdown(tts_value.to_markdown(index = False))"
      ],
      "id": "tbl-y-train-test-values",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen from @tbl-y-train-test-values we have a pretty spread out class with no major class imbalance.\n"
      ],
      "id": "5a4b1f31"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-lr-cross_validate\n",
        "#| tbl-cap: Table of the Cross Validation Scores from Logistic Regression\n",
        "\n",
        "lr_cvs = pd.read_csv(\"results/tables/logistic_regression_df.csv\")\n",
        "lr_value = lr_cvs.iloc[2,1]\n",
        "rounded_lr = round(lr_value, 3)\n",
        "Markdown(lr_cvs.to_markdown(index = False))"
      ],
      "id": "tbl-lr-cross_validate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "One way to get a better understanding of the errors is by looking at how\n",
        "well the classifier is identifying each class. Which classes are most\n",
        "frequently confused with each other. Overall accuracy, along with\n",
        "class-specific metrics like precision, recall, and F1-score for\n",
        "multi-class classification problems.\n",
        "\n",
        "It's easier to demonstrate evaluation metrics using an explicit\n",
        "validation set instead of using cross-validation. So let's create a\n",
        "validation set as seen below in @tbl-confusion-matrix.\n"
      ],
      "id": "879fa24b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-confusion-matrix\n",
        "#| tbl-cap: Table of the Logistic Regression Confusion Matrix\n",
        "\n",
        "lr_cm = pd.read_csv(\"results/tables/confusion_matrix.csv\")\n",
        "Markdown(lr_cm.to_markdown(index = False))"
      ],
      "id": "tbl-confusion-matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better visualize our matrix, the visualization @fig-cm is given\n",
        "below:\n",
        "\n",
        "![Visualization of the Confusion Matrix](results/figures/confusion_matrix.png){#fig-cm width=\"50%\"}\n",
        "\n",
        "\n",
        "We can now calculate our accuracy score given by @tbl-accuracy-score\n",
        "using our `Random Forest Classifier` given below.\n"
      ],
      "id": "9a71a86d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-accuracy-score\n",
        "#| tbl-cap: Table of Accuracy Score From Random Forest Classifier\n",
        "\n",
        "rfc_accuracy = pd.read_csv(\"results/tables/confusion_matrix.csv\")\n",
        "acc_value = rfc_accuracy.iloc[0,0]\n",
        "rounded_acc = round(acc_value, 3)\n",
        "Markdown(rfc_accuracy.to_markdown(index = False))"
      ],
      "id": "tbl-accuracy-score",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this we can provide cross validation scores given in\n",
        "@tbl-rfc-cross_validate using our `Random Forest Classifier`.\n"
      ],
      "id": "6bf97273"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: tbl-rfc-cross_validate\n",
        "#| tbl-cap: Table of the Cross Validation Scores from Random Forest Classifier\n",
        "\n",
        "rfc_cvs = pd.read_csv(\"results/tables/logistic_regression_df.csv\")\n",
        "rfc_value = rfc_cvs.iloc[2,1]\n",
        "rounded_rfc = round(rfc_value, 3)\n",
        "Markdown(rfc_cvs.to_markdown(index = False))"
      ],
      "id": "tbl-rfc-cross_validate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ultimately from our validation scores, we achieve a much higher test\n",
        "score from our scaled data with the RandomForestClassifier model of\n",
        "`{python} rounded_rfc` compared to LogisticRegression model of `{python} rounded_lr`. However our accuracy score is quite low at `{python} rounded_acc`.\n",
        "\n",
        "\n",
        "## Discussion\n",
        "\n",
        "Our model yielded pretty average results with final overall accuracy of\n",
        "`{python} rounded_acc`. This model is not good enough for an automated stellar\n",
        "classification process. In addition, our model can only classify stars\n",
        "into four classes due to the limited sample size. However these four\n",
        "classes make up about 99.8% of stellar population [@ledrew2001real] so\n",
        "being unable to classify stars into remaining three classes isn't as big\n",
        "of an issue. Looking at the confusion matrix, we can see that our model\n",
        "tend to classify stars as cooler than they actually are (e.g: nine stars\n",
        "were classified as *G* but were actually *F* class). In order to improve\n",
        "this model, a larger sample size would help like using the Sloan Digital\n",
        "Sky Survey dataset instead. Another way to improve the model is to\n",
        "explore other classification methods such as k nearest neighbours.\n",
        "Finally, using another photometric system such as UBV could help since\n",
        "the bands are more seperated resulting in larger difference in\n",
        "magnitudes between star classes. More research into other classification\n",
        "methods could most likely yield higher accuracy.\n",
        "\n",
        "\n",
        "## References"
      ],
      "id": "759cd414"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}